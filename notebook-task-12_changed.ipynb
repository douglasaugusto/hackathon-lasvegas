{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge Task 12: Build Multimodal Vector Search for Cymbal Retail\n",
    "\n",
    "## Scenario\n",
    "The **Lumiki Holiday Campaign** is emphasizing \"Smart Home\" visualization. Customers often search using vague terms like \"modern vibe\" or want to find products that *look* like a photo they uploaded. Keyword search isn't enough.\n",
    "\n",
    "## Your Mission\n",
    "You must build a Semantic Search Engine in BigQuery. You will:\n",
    "1.  **Generate Assets:** Create product images and manuals (Code provided).\n",
    "2.  **Text Search:** Generate text embeddings and perform vector search.\n",
    "3.  **Multimodal Search:** Generate multimodal embeddings from images and perform text-to-image search.\n",
    "4.  **Automate:** Use BigQuery's new `AI.EMBED` to automate the process.\n",
    "\n",
    "## Pre-requisites\n",
    "* Completion of Task 13 (Table `cymbal_product_augmented` must exist).\n",
    "* Connection `cymbal_cloud_resource_connection_usc` must be configured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Asset Generation\n",
    "Run the following cells to initialize your environment and generate the visual assets required for multimodal search. \n",
    "\n",
    "**Note:** You do not need to write code for Section 1. Just execute the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID_LIST=!gcloud config list --format \"value(core.project)\" 2>/dev/null\n",
    "PROJECT_ID=PROJECT_ID_LIST[0]\n",
    "PROJECT_NBR_LIST=!gcloud projects describe $PROJECT_ID --format=\"value(projectNumber)\"\n",
    "PROJECT_NBR=PROJECT_NBR_LIST[0]\n",
    "LOCATION=\"us-central1\"\n",
    "\n",
    "# Using the dataset created in Task 13\n",
    "DATASET_ID=\"cymbal_retail_ai_ds\"\n",
    "TABLE_ID=\"cymbal_product_augmented\"\n",
    "BUCKET_NAME=f\"cymbal-multimodal-assets-{PROJECT_NBR}\"\n",
    "\n",
    "print(f\"Project: {PROJECT_ID}\")\n",
    "print(f\"Bucket: {BUCKET_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Storage Bucket for Images\n",
    "!gcloud storage buckets create gs://{BUCKET_NAME} --location={LOCATION}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries for Image Generation\n",
    "%pip install --upgrade --quiet google-genai google-cloud-storage google-cloud-aiplatform reportlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the Service Account ID\n",
    "CONNECTION_PATH = f\"{PROJECT_ID}.us-central1.cymbal_cloud_resource_connection_usc\"\n",
    "DESC_CONN = !bq show --format=prettyjson --connection {CONNECTION_PATH}\n",
    "import json\n",
    "CONN_DATA = json.loads(\"\".join(DESC_CONN))\n",
    "SA_EMAIL = CONN_DATA['cloudResource']['serviceAccountId']\n",
    "\n",
    "print(f\"Authorizing Service Account: {SA_EMAIL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply IAM Policy Bindings\n",
    "!gcloud projects add-iam-policy-binding {PROJECT_ID} --member=serviceAccount:{SA_EMAIL} --role='roles/bigquery.connectionUser' --format=none --condition=None\n",
    "!gcloud projects add-iam-policy-binding {PROJECT_ID} --member=serviceAccount:{SA_EMAIL} --role='roles/aiplatform.user' --format=none --condition=None\n",
    "!gcloud projects add-iam-policy-binding {PROJECT_ID} --member=serviceAccount:{SA_EMAIL} --role='roles/storage.objectViewer' --format=none --condition=None\n",
    "\n",
    "import time\n",
    "print(\"Waiting for IAM propagation (60s)...\")\n",
    "time.sleep(80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Execute Image Generation Script\n",
    "Run the cell below. It will read your `cymbal_product_augmented` table, call Vertex AI to generate images for the products, and save them to GCS. \n",
    "\n",
    "**Wait for this to complete before proceeding.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_gbq\n",
    "import time\n",
    "from io import BytesIO\n",
    "from IPython.display import Image, Markdown, display\n",
    "from google import genai\n",
    "from google.genai.types import FinishReason, GenerateContentConfig, ImageConfig\n",
    "from google.cloud import storage\n",
    "\n",
    "# Setup Clients\n",
    "genai_client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "model_flavor = \"gemini-2.5-flash-image\"\n",
    "\n",
    "def generate_and_persist_image(product_id, product_nm, product_desc):\n",
    "    prompt = f\"Generate a high-resolution commercial product image for {product_nm}. Description: {product_desc}. White background, studio lighting.\"\n",
    "    output_path = f\"generated_images/{product_id}.png\"\n",
    "\n",
    "    try:\n",
    "        response = genai_client.models.generate_content(\n",
    "            model=model_flavor, contents=prompt,\n",
    "            config=GenerateContentConfig(\n",
    "                response_modalities=[\"IMAGE\"],\n",
    "                image_config=ImageConfig(aspect_ratio=\"1:1\"),\n",
    "                candidate_count=1\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Error Handling\n",
    "        if not response.candidates or response.candidates[0].finish_reason != FinishReason.STOP:\n",
    "            reason = response.candidates[0].finish_reason if response.candidates else \"No candidates\"\n",
    "            print(f\"Error {product_id}: Prompt Content Error: {reason}\")\n",
    "            return None\n",
    "\n",
    "        # Processing & Uploading\n",
    "        for part in response.candidates[0].content.parts:\n",
    "            if part.inline_data:\n",
    "                bucket = storage_client.bucket(BUCKET_NAME)\n",
    "                blob = bucket.blob(output_path)\n",
    "                blob.upload_from_file(\n",
    "                    BytesIO(part.inline_data.data),\n",
    "                    content_type=part.inline_data.mime_type\n",
    "                )\n",
    "                print(f\"Generated: {output_path}\")\n",
    "                return f\"gs://{BUCKET_NAME}/{output_path}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error {product_id}: {e}\")\n",
    "    return None\n",
    "\n",
    "# Fetch Data\n",
    "sql = f\"SELECT product_id, product_nm, product_description FROM `{PROJECT_ID}.{DATASET_ID}.{TABLE_ID}`\"\n",
    "df = pandas_gbq.read_gbq(sql, project_id=PROJECT_ID)\n",
    "\n",
    "# Run Generation\n",
    "for index, row in df.iterrows():\n",
    "    uri = generate_and_persist_image(row['product_id'], row['product_nm'], row['product_description'])\n",
    "    df.at[index, 'product_image_gcs_uri'] = uri\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Update BigQuery with Image URIs\n",
    "Now that images are in GCS, we update the table references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "bq_client = bigquery.Client()\n",
    "\n",
    "update_query = f\"\"\"\n",
    "    UPDATE `{DATASET_ID}.{TABLE_ID}`\n",
    "    SET product_image_gcs_uri = CONCAT('gs://{BUCKET_NAME}/generated_images/', product_id, '.png')\n",
    "    WHERE TRUE\n",
    "\"\"\"\n",
    "query_job = bq_client.query(update_query)\n",
    "query_job.result()\n",
    "print(\"Table updated with Image URIs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Challenge: Text-to-Text Vector Search\n",
    "Now the real work begins. You need to enable semantic search so users can find products by meaning, not just keywords.\n",
    "\n",
    "### 2.1 Create Text Embedding Model\n",
    "**TODO:** Create a remote model named `cymbal_text_embedding_model` that points to `gemini-embedding-001`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project {PROJECT_ID}\n",
    "\n",
    "CREATE OR REPLACE MODEL `cymbal_retail_ai_ds.cymbal_text_embedding_model`\n",
    "REMOTE WITH CONNECTION `us-central1.cymbal_cloud_resource_connection_usc`\n",
    "OPTIONS (ENDPOINT = 'gemini-embedding-001');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Generate Text Embeddings\n",
    "**TODO:** \n",
    "1. Add a column `text_embedding` (ARRAY<FLOAT64>) to `cymbal_product_augmented`.\n",
    "2. Use `ML.GENERATE_EMBEDDING` to populate it using the product name and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project {PROJECT_ID}\n",
    "\n",
    "-- TODO: ALTER TABLE to add text_embedding column\n",
    "ALTER TABLE `cymbal_retail_ai_ds.cymbal_product_augmented`\n",
    "ADD COLUMN IF NOT EXISTS text_embedding ARRAY<FLOAT64>;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project {PROJECT_ID}\n",
    "\n",
    "UPDATE `cymbal_retail_ai_ds.cymbal_product_augmented`\n",
    "SET text_embedding = (\n",
    "    SELECT ml_generate_embedding_result\n",
    "    FROM ML.GENERATE_EMBEDDING(\n",
    "        MODEL `cymbal_retail_ai_ds.cymbal_text_embedding_model`,\n",
    "        (SELECT CONCAT(product_nm, ' ', product_description) AS content)\n",
    "    )\n",
    ")\n",
    "WHERE TRUE;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Perform Vector Search\n",
    "**TODO:** Perform a vector search to find products similar to the query: **\"fabric steamer\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project {PROJECT_ID}\n",
    "\n",
    "SELECT base.product_nm, base.product_description, distance\n",
    "FROM VECTOR_SEARCH(\n",
    "    TABLE `cymbal_retail_ai_ds.cymbal_product_augmented`,\n",
    "    'text_embedding',\n",
    "    (SELECT ml_generate_embedding_result\n",
    "     FROM ML.GENERATE_EMBEDDING(\n",
    "         MODEL `cymbal_retail_ai_ds.cymbal_text_embedding_model`,\n",
    "         (SELECT \"fabric steamer\" AS content)\n",
    "     )\n",
    "    ),\n",
    "    top_k => 3\n",
    ")\n",
    "ORDER BY distance ASC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task Validation\n",
    "Task Complete! \n",
    "> **Note:** Go back to the lab guide page and click **Check my progress** for **AT ID: 7141 Text-to-Text Vector Search**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Challenge: Multimodal Search (Text-to-Image)\n",
    "Cymbal wants users to search for products based on how they *look*.\n",
    "\n",
    "### 3.1 Create Multimodal Model\n",
    "**TODO:** Create `cymbal_multimodal_model` pointing to `multimodalembedding@001`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project {PROJECT_ID}\n",
    "\n",
    "CREATE OR REPLACE MODEL `cymbal_retail_ai_ds.cymbal_multimodal_model`\n",
    "REMOTE WITH CONNECTION `us-central1.cymbal_cloud_resource_connection_usc`\n",
    "OPTIONS (ENDPOINT = 'multimodalembedding@001');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Generate Image Embeddings\n",
    "**TODO:** \n",
    "1. Add column `mm_embedding` (ARRAY<FLOAT64>).\n",
    "2. Update the table. This is the hardest part. You must use `OBJ.MAKE_REF`, `OBJ.FETCH_METADATA`, and `OBJ.GET_ACCESS_URL` chain to convert the GCS URI into something the model can read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project {PROJECT_ID}\n",
    "\n",
    "ALTER TABLE `cymbal_retail_ai_ds.cymbal_product_augmented`\n",
    "ADD COLUMN IF NOT EXISTS mm_embedding ARRAY<FLOAT64>;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project {PROJECT_ID}\n",
    "\n",
    "UPDATE `cymbal_retail_ai_ds.cymbal_product_augmented`\n",
    "SET mm_embedding = (\n",
    "    SELECT ml_generate_embedding_result\n",
    "    FROM ML.GENERATE_EMBEDDING(\n",
    "        MODEL `cymbal_retail_ai_ds.cymbal_multimodal_model`,\n",
    "        (SELECT product_id, OBJ.GET_ACCESS_URL(OBJ.FETCH_METADATA(OBJ.MAKE_REF(product_image_gcs_uri))) AS content\n",
    "         FROM `cymbal_retail_ai_ds.cymbal_product_augmented` AS inner_table\n",
    "         WHERE inner_table.product_id = `cymbal_retail_ai_ds.cymbal_product_augmented`.product_id)\n",
    "    )\n",
    ")\n",
    "WHERE TRUE;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Perform Text-to-Image Search\n",
    "**TODO:** Search for **\"modern white appliances\"**. This time, the search must match against the **Image Embeddings (`mm_embedding`)**, not the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project {PROJECT_ID}\n",
    "\n",
    "SELECT base.product_nm, base.product_image_gcs_uri, distance\n",
    "FROM VECTOR_SEARCH(\n",
    "    TABLE `cymbal_retail_ai_ds.cymbal_product_augmented`,\n",
    "    'mm_embedding',\n",
    "    (SELECT ml_generate_embedding_result\n",
    "     FROM ML.GENERATE_EMBEDDING(\n",
    "         MODEL `cymbal_retail_ai_ds.cymbal_multimodal_model`,\n",
    "         (SELECT \"modern white appliances\" AS content)\n",
    "     )\n",
    "    ),\n",
    "    top_k => 3\n",
    ")\n",
    "ORDER BY distance ASC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task Validation\n",
    "Task Complete! \n",
    "> **Note:** Go back to the lab guide page and click **Check my progress** for **AT ID: 7142 Multimodal Search (Text-to-Image)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Challenge: Automated Embeddings (AI.EMBED)\n",
    "Manually updating embeddings is slow. Use BigQuery's `GENERATED ALWAYS AS` syntax to automate this.\n",
    "\n",
    "### 4.1 Create Auto-Embedding Table\n",
    "**TODO:** Create a table `cymbal_product_auto_embedding` that automatically generates embeddings for `product_description` using `text-embedding-005`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project {PROJECT_ID}\n",
    "\n",
    "CREATE OR REPLACE TABLE `cymbal_retail_ai_ds.cymbal_product_auto_embedding` (\n",
    "    product_id STRING,\n",
    "    product_nm STRING,\n",
    "    product_description STRING,\n",
    "    embedding STRUCT<result ARRAY<FLOAT64>, status STRING>\n",
    "        GENERATED ALWAYS AS (AI.EMBED(product_description, 'text-embedding-005'))\n",
    "        STORED\n",
    "        OPTIONS(asynchronous = TRUE)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Insert and Verify\n",
    "**TODO:** Insert data from the augmented table into the auto-embedding table and verify the embeddings are generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project {PROJECT_ID}\n",
    "\n",
    "INSERT INTO `cymbal_retail_ai_ds.cymbal_product_auto_embedding` (product_id, product_nm, product_description)\n",
    "SELECT product_id, product_nm, product_description\n",
    "FROM `cymbal_retail_ai_ds.cymbal_product_augmented`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project {PROJECT_ID}\n",
    "\n",
    "-- Validate\n",
    "SELECT * FROM `cymbal_retail_ai_ds.cymbal_product_auto_embedding` LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task Validation\n",
    "Task Complete! \n",
    "> **Note:** Go back to the lab guide page and click **Check my progress** for **AT ID 7143 Automated Embeddings (AI.EMBED)**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
